import streamlit as st
import uuid
from openai import OpenAI

# å¯¼å…¥æ‰€æœ‰æ¨¡å— (ä¿æŒä¸å˜)
from modules.embedder import load_embedder
from modules.processor import process_file
from modules.web_search import search_web
from modules.history import save_chat, load_chat, get_history_list, delete_chat
from modules.database import add_to_db, reset_db, get_collection, get_all_files, delete_file_from_db
from modules.retriever import search_vectors
from modules.reranker import load_reranker

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="DeepSeek Pro çŸ¥è¯†åº“", layout="wide", page_icon="ğŸ§ ")


def main():
    st.title("ğŸ¤– DeepSeek Pro çŸ¥è¯†åº“ (v4.1)")
    st.caption("å…¨åŠŸèƒ½ç‰ˆ: å¼•ç”¨æŒä¹…åŒ– | å‚æ•°è¯¦è§£ | æ·±åº¦æ€è€ƒ")

    # --- Session State åˆå§‹åŒ– ---
    if "messages" not in st.session_state: st.session_state.messages = []
    if "current_chat_id" not in st.session_state: st.session_state.current_chat_id = str(uuid.uuid4())

    # --- ä¾§è¾¹æ  ---
    with st.sidebar:
        tab1, tab2 = st.tabs(["âš™ï¸ æ§åˆ¶å°", "ğŸ•’ å†å²"])

        # === Tab 1: è®¾ç½®ä¸ç®¡ç† ===
        with tab1:
            # 1. æ¨¡å‹çŠ¶æ€ä»ªè¡¨ç›˜
            st.subheader("1. ç³»ç»ŸçŠ¶æ€")
            ds_key = st.secrets.get("DEEPSEEK_API_KEY")
            ds_url = st.secrets.get("DEEPSEEK_BASE_URL", "https://api.deepseek.com")
            emb_key = st.secrets.get("EMBEDDING_API_KEY")
            emb_base = st.secrets.get("EMBEDDING_BASE_URL")
            emb_model = st.secrets.get("EMBEDDING_MODEL")
            rerank_key = st.secrets.get("RERANK_API_KEY")
            rerank_base = st.secrets.get("RERANK_BASE_URL")
            rerank_model = st.secrets.get("RERANK_MODEL")
            tavily_key = st.secrets.get("TAVILY_API_KEY")

            c1, c2, c3 = st.columns(3)
            c1.markdown("ğŸŸ¢ **LLM**" if ds_key else "ğŸ”´ **LLM**")
            c2.markdown("ğŸŸ¢ **RAG**" if emb_key else "ğŸ”´ **RAG**")
            c3.markdown("ğŸŸ¢ **Web**" if tavily_key else "âšª **Web**")

            st.divider()

            # 2. çŸ¥è¯†åº“ä¸Šä¼ 
            st.subheader("2. å¯¼å…¥æ–‡æ¡£")
            files = st.file_uploader("ä¸Šä¼  PDF/Word", accept_multiple_files=True)
            if st.button("ğŸš€ å­˜å…¥çŸ¥è¯†åº“", type="primary") and files:
                if not emb_key: st.stop()
                embedder = load_embedder(emb_key, emb_base, emb_model)
                total = 0
                prog = st.progress(0)
                for i, f in enumerate(files):
                    fc, fv, _ = process_file(embedder, f.name, f.getvalue())
                    if fc: total += add_to_db(fc, fv)
                    prog.progress((i + 1) / len(files))
                if total > 0: st.success(f"å­˜å…¥ {total} ç‰‡æ®µ")
                st.rerun()

            # 3. æ–‡ä»¶ç®¡ç†åˆ—è¡¨
            st.subheader("3. æ–‡ä»¶ç®¡ç†")
            existing_files = get_all_files()
            if existing_files:
                with st.expander(f"å·²å­˜å‚¨ {len(existing_files)} ä¸ªæ–‡ä»¶", expanded=False):
                    for f in existing_files:
                        c1, c2 = st.columns([0.85, 0.15])
                        c1.text(f[:20] + "..." if len(f) > 20 else f)
                        if c2.button("ğŸ—‘ï¸", key=f"del_{f}"):
                            delete_file_from_db(f)
                            st.rerun()
                if st.button("ğŸ’£ æ¸…ç©ºæ‰€æœ‰æ•°æ®"):
                    reset_db()
                    st.rerun()
            else:
                st.caption("çŸ¥è¯†åº“ä¸ºç©º")

            st.divider()

            # 4. ğŸŸ¢ ä¼˜åŒ–ï¼šé«˜çº§å‚æ•°è®¾ç½® (å¸¦è¯¦ç»†è¯´æ˜)
            with st.expander("ğŸ›ï¸ å‚æ•°å¾®è°ƒ (æ–°æ‰‹å¿…è¯»)"):
                st.markdown("""
                **å‚æ•°è¯´æ˜ä¹¦ï¼š**
                * **åˆ›é€ æ€§**: è¶Šä½è¶Šä¸¥è°¨(é€‚åˆç§‘ç ”)ï¼Œè¶Šé«˜è¶Šå‘æ•£(é€‚åˆåˆ›æ„)ã€‚
                * **ç²—æ’ (Recall)**: ä»æ•°æ®åº“é‡Œå…ˆæå‡ºå¤šå°‘æ¡â€œå¯èƒ½ç›¸å…³â€çš„å†…å®¹ã€‚
                * **ç²¾æ’ (Rerank)**: è®© AI è€å¸ˆä»”ç»†æ‰“åˆ†ï¼Œæœ€ç»ˆç»™å¤§æ¨¡å‹çœ‹å‰å‡ åã€‚
                """)

                temperature = st.slider(
                    "åˆ›é€ æ€§ (Temperature)", 0.0, 1.3, 0.3, 0.1,
                    help="å»ºè®®ï¼šç§‘ç ”æŸ¥è¯¢è®¾ä¸º 0.1ï¼Œæ—¥å¸¸å¯¹è¯è®¾ä¸º 0.7"
                )
                top_k_recall = st.slider(
                    "ç²—æ’æ•°é‡ (Recall)", 10, 100, 50,
                    help="å¢åŠ æ­¤å€¼å¯å‡å°‘æ¼æ‰¾ï¼Œä½†ä¼šå¢åŠ  Rerank æ—¶é—´"
                )
                top_k_rerank = st.slider(
                    "ç²¾æ’æ•°é‡ (Rerank)", 1, 10, 5,
                    help="æœ€ç»ˆå–‚ç»™ DeepSeek çš„ç‰‡æ®µæ•°ã€‚å»ºè®® 5 å·¦å³ï¼Œå¤ªå¤šä¼šå¹²æ‰°æ¨¡å‹"
                )
                use_web = st.toggle("è”ç½‘å¢å¼º", value=False)

            if st.button("â• æ–°å»ºå¯¹è¯"):
                st.session_state.messages = []
                st.session_state.current_chat_id = str(uuid.uuid4())
                st.rerun()

        # === Tab 2: å†å² ===
        with tab2:
            for chat in get_history_list():
                c1, c2 = st.columns([0.85, 0.15])
                label = f"**{chat['title']}**\n\n_{chat['timestamp'][5:-3]}_"
                if c1.button(label, key=f"h_{chat['id']}", use_container_width=True):
                    st.session_state.messages = load_chat(chat['id'])
                    st.session_state.current_chat_id = chat['id']
                    st.rerun()
                if c2.button("âŒ", key=f"d_{chat['id']}"):
                    delete_chat(chat['id'])
                    st.rerun()

    # --- ğŸŸ¢ ä¼˜åŒ–ï¼šèŠå¤©ä¸»ç•Œé¢ (æ”¯æŒå†å²å¼•ç”¨æ¸²æŸ“) ---
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])
            # å…³é”®ä¿®æ”¹ï¼šå¦‚æœå†å²æ¶ˆæ¯é‡ŒåŒ…å« sources å­—æ®µï¼Œåˆ™æ¸²æŸ“æŠ˜å æ¡†
            if "sources" in msg and msg["sources"]:
                with st.expander("ğŸ“– æŸ¥çœ‹å¼•ç”¨ç‰‡æ®µ (Source Context)"):
                    st.info(msg["sources"])

    query = st.chat_input("å‘çŸ¥è¯†åº“æé—®...")

    if query:
        st.session_state.messages.append({"role": "user", "content": query})
        with st.chat_message("user"):
            st.write(query)

        local_context = ""
        web_context = ""

        # å¯è§†åŒ–æ€è€ƒè¿‡ç¨‹
        with st.status("ğŸš€ AI æ­£åœ¨æ·±åº¦æ€è€ƒ...", expanded=True) as status:

            # Step 1: æœ¬åœ°æ£€ç´¢
            if get_collection().count() > 0:
                st.write("ğŸ“š æ­£åœ¨æ£€ç´¢æœ¬åœ°çŸ¥è¯†åº“...")
                embedder = load_embedder(emb_key, emb_base, emb_model)
                reranker = load_reranker(rerank_key, rerank_base, rerank_model)

                local_context = search_vectors(
                    embedder, query, reranker,
                    top_k_recall=top_k_recall,
                    top_k_rerank=top_k_rerank
                )
                if local_context:
                    st.write(f"âœ… æ‰¾åˆ° {top_k_rerank} ä¸ªç›¸å…³ç‰‡æ®µ (å·²é‡æ’åº)")
                else:
                    st.write("âš ï¸ æœ¬åœ°æœªæ‰¾åˆ°è¶³å¤Ÿç›¸å…³å†…å®¹")

            # Step 2: è”ç½‘æœç´¢
            if use_web and tavily_key:
                st.write("ğŸŒ æ­£åœ¨æ‰«æäº’è”ç½‘æœ€æ–°ä¿¡æ¯...")
                web_context = search_web(query, tavily_key)
                st.write("âœ… äº’è”ç½‘æ•°æ®è·å–æˆåŠŸ")

            status.update(label="ğŸ§  æ€è€ƒå®Œæˆï¼Œæ­£åœ¨ç”Ÿæˆå›ç­”", state="complete", expanded=False)

        # ç»„è£… Prompt
        prompt = ""
        if local_context: prompt += f"ã€æœ¬åœ°çŸ¥è¯†ã€‘:\n{local_context}\n\n"
        if web_context: prompt += f"ã€ç½‘ç»œä¿¡æ¯ã€‘:\n{web_context}\n\n"

        system_prompt = f"è¯·åŸºäºä»¥ä¸‹èƒŒæ™¯å›ç­”é—®é¢˜ã€‚å¿…é¡»æ ‡æ³¨æ¥æº [æ¥æº: xxx]ã€‚\n\n{prompt}"

        # ç”Ÿæˆå›ç­”
        client = OpenAI(api_key=ds_key, base_url=ds_url)
        with st.chat_message("assistant"):
            try:
                stream = client.chat.completions.create(
                    model="deepseek-chat",
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": query}
                    ],
                    temperature=temperature,
                    stream=True
                )
                response = st.write_stream(stream)

                # ğŸŸ¢ ä¼˜åŒ–ï¼šä¿å­˜æ—¶å°† sources ä¹Ÿå­˜å…¥ history
                message_data = {
                    "role": "assistant",
                    "content": response,
                    "sources": local_context  # å°†å¼•ç”¨å†…å®¹æŒä¹…åŒ–ä¿å­˜
                }
                st.session_state.messages.append(message_data)
                save_chat(st.session_state.current_chat_id, st.session_state.messages)

                # å½“å‰è½®æ¬¡çš„å¼•ç”¨å±•ç¤º (ä¸ºäº†å³æ—¶åé¦ˆ)
                if local_context:
                    with st.expander("ğŸ“– æŸ¥çœ‹å¼•ç”¨ç‰‡æ®µ (Source Context)"):
                        st.info(local_context)

            except Exception as e:
                st.error(f"Error: {e}")


if __name__ == "__main__":
    main()